{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib_inline import backend_inline\n",
    "from IPython import display\n",
    "import ast\n",
    "from wordcloud import WordCloud\n",
    "from urllib.parse import unquote\n",
    "from utils import calculate_CR, calculate_NDCG, recommend_N, calculate_popularity, calculate_Gini, calculate_popular_track_ratio\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "track_count_df = pd.read_csv('../data/track_count.csv')\n",
    "\n",
    "track_playcount_list = track_count_df['playcount'].tolist()\n",
    "track_user_count_list = track_count_df['user_count'].tolist()\n",
    "\n",
    "num_tracks = track_count_df['serial_number'].max() + 1\n",
    "print(f'{num_tracks} tracks in filtered data')\n",
    "\n",
    "user_events_file = '../data/topic_model_train.csv'\n",
    "user_events_df = pd.read_csv(user_events_file)\n",
    "user_events_list = []\n",
    "\n",
    "user_listen_count_list = user_events_df['listen_count_intensity'].tolist()\n",
    "\n",
    "for index, row in user_events_df.iterrows():\n",
    "    listen_list = ast.literal_eval(row['train_set'])\n",
    "    user_events_list.append(listen_list)\n",
    "\n",
    "predict_candidate_df = pd.read_csv('../data/predict_performance_test.csv')\n",
    "predict_candidate_list = []\n",
    "for index, row in predict_candidate_df.iterrows():\n",
    "    row_list = ast.literal_eval(row['test_set'])\n",
    "    predict_candidate_list.append(row_list)\n",
    "\n",
    "num_users = len(predict_candidate_df)\n",
    "print(f'{num_users} users in filtered data')\n",
    "\n",
    "max_length = max([len(user_lists) for user_lists in user_events_list])\n",
    "min_length = min([len(user_lists) for user_lists in user_events_list])\n",
    "print('max_length = ', max_length)\n",
    "print('min_length = ', min_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_name_list = track_count_df['name'].tolist()\n",
    "\n",
    "def parse_and_truncate_names(name_list):\n",
    "    parsed_names = []\n",
    "\n",
    "    for name in name_list:\n",
    "        name_without_plus = name.replace('+', '')\n",
    "        decoded_name = unquote(name_without_plus)\n",
    "        artist, song = decoded_name.split('/_/')\n",
    "        truncated_artist = artist[:14]\n",
    "        truncated_song = song[:14]\n",
    "        formatted_name = f\"{truncated_artist}:{truncated_song}\"\n",
    "        parsed_names.append(formatted_name)\n",
    "    \n",
    "    return parsed_names\n",
    "\n",
    "parsed_name_list = parse_and_truncate_names(track_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playcounts = track_playcount_list\n",
    "\n",
    "df_playcounts = pd.DataFrame({'playcount': playcounts})\n",
    "playcount_dict = df_playcounts.playcount.value_counts().to_dict()\n",
    "\n",
    "plt.figure(figsize=(4.5, 3.5), dpi=100)\n",
    "plt.scatter(list(playcount_dict.keys()), list(playcount_dict.values()), s=2)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.title('Playcount Distribution')\n",
    "plt.xlabel('Number of Plays', fontsize=13)\n",
    "plt.ylabel('Number of Tracks', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(sorted(track_playcount_list))\n",
    "plt.xlabel('Track (log)', fontsize='14')\n",
    "plt.xticks(fontsize='13')\n",
    "plt.yticks(fontsize='13')\n",
    "plt.ylabel('Number of listeners (log)', fontsize='15')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playcounts_series = pd.Series(playcounts)\n",
    "\n",
    "playcount_stats = playcounts_series.describe()\n",
    "\n",
    "print(f'playcount_stats:\\n{playcount_stats}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_svg_display():\n",
    "    #@save\n",
    "    backend_inline.set_matplotlib_formats('svg')\n",
    "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.set_xscale(xscale)\n",
    "    axes.set_yscale(yscale)\n",
    "    axes.set_xlim(xlim)\n",
    "    axes.set_ylim(ylim)\n",
    "    if legend:\n",
    "        axes.legend(legend)\n",
    "    axes.grid()\n",
    "class Animator:\n",
    "    #@save\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                ylim=None, xscale='linear', yscale='linear',\n",
    "                fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                figsize=(3.5, 2.5)):\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        use_svg_display()\n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        self.config_axes = lambda: set_axes(self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def add(self, x, y):\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_batch_generator(wordOccuranceMatrix, rho_matrix, eta_matrix, n, V):\n",
    "    flattened_wordOccuranceMatrix = wordOccuranceMatrix.view(-1)\n",
    "    flattened_rho_matrix = rho_matrix.view(-1)\n",
    "    flattened_eta_matrix = eta_matrix.contiguous().view(-1, eta_matrix.shape[-1])\n",
    "\n",
    "    for i in range(0, wordOccuranceMatrix.numel(), n):\n",
    "        indices = flattened_wordOccuranceMatrix[i:i+n]\n",
    "        current_batch_size = indices.shape[0]\n",
    "        \n",
    "        y = torch.zeros(current_batch_size, V, device=device)\n",
    "        y.scatter_(1, indices.unsqueeze(1), 1)\n",
    "        \n",
    "        vector_batch = flattened_rho_matrix[i:i+current_batch_size]\n",
    "        tensor_batch = flattened_eta_matrix[i:i+current_batch_size]\n",
    "        \n",
    "        yield torch.einsum('nv, n, nk -> kv', [y, vector_batch, tensor_batch])\n",
    "\n",
    "def sigma_batch_generator(wordOccuranceMatrix, rho_matrix, n, V):\n",
    "    flattened_wordOccuranceMatrix = wordOccuranceMatrix.view(-1)\n",
    "    flattened_rho_matrix = rho_matrix.view(-1)\n",
    "\n",
    "    for i in range(0, wordOccuranceMatrix.numel(), n):\n",
    "        indices = flattened_wordOccuranceMatrix[i:i+n]\n",
    "        current_batch_size = indices.shape[0]  \n",
    "\n",
    "        y = torch.zeros(current_batch_size, V, device=device)\n",
    "        y.scatter_(1, indices.unsqueeze(1), 1)\n",
    "        \n",
    "        vector_batch = flattened_rho_matrix[i:i+current_batch_size]\n",
    "        \n",
    "        yield torch.einsum('nv, n -> v', [y, vector_batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HB_Rec:\n",
    "    def __init__(self, num_topics, alpha, beta, gamma, zeta, delta, cq, random_state, mu_batch, sigma_batch, num_tracks, predict_candidate_list):\n",
    "        self.predict_candidate_list = predict_candidate_list\n",
    "        self.num_topics = num_topics\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.zeta = zeta\n",
    "        self.delta = delta\n",
    "\n",
    "        self.num_words = torch.tensor(num_tracks, device=device, dtype=torch.int32)\n",
    "        self.cq = torch.tensor(cq, dtype=torch.float32, device=device)\n",
    "\n",
    "        self.random_state = random_state\n",
    "        self.mu_batch = mu_batch\n",
    "        self.sigma_batch = sigma_batch\n",
    "\n",
    "        np.random.seed(self.random_state)\n",
    "        torch.manual_seed(self.random_state)\n",
    "        if torch.cuda.is_available(): \n",
    "            torch.cuda.manual_seed(self.random_state)\n",
    "            torch.cuda.manual_seed_all(self.random_state)\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "    def processProfiles(self, user_events_list, user_count_list):\n",
    "        self.Nu = torch.tensor([len(user_list) for user_list in user_events_list], device=device, dtype=torch.int32)\n",
    "        self.num_docs = torch.tensor(len(user_events_list), device=device, dtype=torch.int32)\n",
    "        self.num_intensity = torch.tensor(max(user_count_list) + 1, device=device, dtype=torch.int32)\n",
    "        self.max_len = torch.max(self.Nu).to(device).to(torch.int32)\n",
    "        \n",
    "        self.alpha = self.alpha * torch.ones(self.num_topics, device=device)\n",
    "        self.beta = self.beta * torch.ones(self.num_words, device=device)\n",
    "        self.gamma = torch.tensor(self.gamma, device=device)\n",
    "        self.zeta = self.zeta * torch.ones(self.num_words, device=device)\n",
    "        self.delta = self.delta * torch.ones(self.num_intensity, device=device)\n",
    "\n",
    "        self.mask = torch.tensor([[1] * len(user_list) + [0] * (self.max_len - len(user_list)) for user_list in user_events_list], dtype=torch.bool, device=device)\n",
    "\n",
    "        self.tau = (torch.distributions.Gamma(100.0, 0.01).sample((self.num_docs, self.num_topics))).to(device)\n",
    "        eta = torch.einsum('unk, un -> unk', [torch.distributions.Dirichlet(torch.ones(self.num_docs, self.max_len, self.num_topics)).sample().to(device), self.mask])\n",
    "        self.eta = eta.to('cuda:1')\n",
    "        del eta\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        self.rho = (torch.einsum('un, un -> un', [torch.distributions.Beta(torch.ones(self.num_docs, self.max_len), torch.ones(self.num_docs, self.max_len)).sample().to(device), self.mask]))\n",
    "        self.lamda = torch.distributions.Gamma(100.0, 0.01).sample((self.num_docs, 2)).to(device)\n",
    "        self.iota = torch.distributions.Beta(torch.ones(self.num_docs), torch.ones(self.num_docs)).sample().to(device)\n",
    "        self.mu = torch.distributions.Gamma(100.0, 0.01).sample((self.num_topics, self.num_words)).to(device)\n",
    "        self.sigma = torch.distributions.Gamma(100.0, 0.01).sample((self.num_words, )).to(device)\n",
    "        self.kappa = torch.distributions.Gamma(100.0, 0.01).sample((2, self.num_intensity)).to(device)\n",
    "        self.wordOccuranceMatrix = torch.tensor([user_list + [0] * (self.max_len - len(user_list)) for user_list in user_events_list], dtype=torch.int64) # NOTE: Fill it with 0 because it will be indexed late\n",
    "        self.user_count_list = torch.tensor(user_count_list, device=device)\n",
    "\n",
    "        self.ELBO = []\n",
    "    \n",
    "    def ref_update_variational_parameters(self):\n",
    "        mu_kun = torch.stack([self.mu[k].index_select(0, self.wordOccuranceMatrix.view(-1).to(device)).view(self.wordOccuranceMatrix.shape) for k in range(self.num_topics)])\n",
    "        self.mu_kun = mu_kun.to('cuda:1')\n",
    "        del mu_kun\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        self.sigma_un = self.sigma[self.wordOccuranceMatrix]\n",
    "        self.kappa_u = self.kappa[:, self.user_count_list]\n",
    "        \n",
    "        for iter in range(50):\n",
    "            self.tau = torch.einsum('unk -> uk', [self.eta.to('cuda:0')]) + self.alpha\n",
    "\n",
    "            eta_factor1 = (torch.digamma(self.tau) - torch.digamma(torch.sum(self.tau, dim=1)).unsqueeze(1)).unsqueeze(1) \n",
    "            # eta_factor2 = torch.einsum('un, unk -> unk', [(1 - self.rho) * self.mask, torch.digamma(self.mu_kun).to('cuda:0').permute(1, 2, 0) - torch.digamma(torch.sum(self.mu, dim=1))]) # u*n*k\n",
    "            \n",
    "            eta_factor2 =torch.zeros((self.num_docs, self.max_len, self.num_topics), device='cuda:0')\n",
    "            for start in range(0, self.num_topics, 25):\n",
    "                end = min(start + 25, self.num_topics)\n",
    "\n",
    "                mu_kun_chunk = self.mu_kun[start:end, :, :]\n",
    "                mu_chunk = self.mu[start:end, :]\n",
    "\n",
    "                mu_kun_permuted = torch.digamma(mu_kun_chunk).permute(1, 2, 0).to('cuda:0')\n",
    "\n",
    "                digamma_mu_sum = torch.digamma(torch.sum(mu_chunk, dim=1))\n",
    "\n",
    "                eta_factor2[:, :, start:end] = torch.einsum(\n",
    "                    'un, unk -> unk', \n",
    "                    [(1 - self.rho) * self.mask, mu_kun_permuted - digamma_mu_sum]\n",
    "                )\n",
    "            \n",
    "            shifted_matrix = eta_factor1 + eta_factor2 - torch.max(eta_factor1 + eta_factor2, dim=2)[0].unsqueeze(2)\n",
    "            del eta_factor1, eta_factor2\n",
    "            eta = torch.einsum('unk, un -> unk', [torch.exp(shifted_matrix).div_(torch.exp(shifted_matrix).sum(dim=-1, keepdim=True)), self.mask])\n",
    "            self.eta = eta.cpu()\n",
    "            del eta, shifted_matrix\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            rho_factor1 = -(torch.digamma(self.sigma_un) * self.mask) + torch.digamma(torch.sum(self.sigma)) # u*n\n",
    "            # rho_factor2 = torch.einsum('unk, unk -> un', [self.eta.to('cuda:0'), torch.digamma(self.mu_kun).to('cuda:0').permute(1, 2, 0) - torch.digamma(torch.sum(self.mu, dim=1))]) # u*n\n",
    "            \n",
    "            rho_factor2 = torch.zeros((self.num_docs, self.max_len), device='cuda:0')\n",
    "            for start in range(0, self.num_topics, 25):\n",
    "                end = min(start + 25, self.num_topics)\n",
    "\n",
    "                eta_unk_chunk = self.eta.to('cuda:0')[:, :, start:end]\n",
    "                mu_kun_chunk = self.mu_kun[start:end, :, :]\n",
    "                mu_chunk = self.mu[start:end, :]\n",
    "\n",
    "                mu_kun_permuted = torch.digamma(mu_kun_chunk).permute(1, 2, 0).to('cuda:0')\n",
    "\n",
    "                digamma_mu_sum = torch.digamma(torch.sum(mu_chunk, dim=1))\n",
    "\n",
    "                rho_factor2 += torch.einsum(\n",
    "                    'unk, unk -> un', \n",
    "                    [eta_unk_chunk, mu_kun_permuted - digamma_mu_sum]\n",
    "                )\n",
    "\n",
    "            rho_factor3 = (torch.digamma(self.lamda[: , 1]) - torch.digamma(self.lamda[: , 0])).unsqueeze(1) \n",
    "            exp_sum_rho_factor = torch.exp(rho_factor1 + rho_factor2 + rho_factor3)\n",
    "            del rho_factor1, rho_factor2, rho_factor3\n",
    "            self.rho = torch.einsum('un, un -> un', [1 / (1 + exp_sum_rho_factor), self.mask])\n",
    "            del exp_sum_rho_factor\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            self.lamda = torch.stack((torch.sum(self.rho, dim=1) + self.iota + self.gamma[0], torch.sum((1 - self.rho) * self.mask, dim=1) + 1 - self.iota + self.gamma[1])).T\n",
    "\n",
    "            iota_factor1 = -torch.digamma(self.lamda[:, 0]) + torch.digamma(self.lamda[:, 1])\n",
    "            iota_factor2 = torch.digamma(self.kappa_u[0, :]) - torch.digamma(self.kappa_u[1, :])\n",
    "            iota_factor3 = -torch.digamma(torch.sum(self.kappa[0])) + torch.digamma(torch.sum(self.kappa[1]))\n",
    "            exp_sum_iota_factor = torch.exp(iota_factor1 + iota_factor2 + iota_factor3)\n",
    "            self.iota = 1 / (1 + exp_sum_iota_factor)\n",
    "            del iota_factor1, iota_factor2, iota_factor3, exp_sum_iota_factor\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        self.mu = torch.ones(self.num_topics, self.num_words, device=device) * self.beta\n",
    "        for tmp_mu in mu_batch_generator(self.wordOccuranceMatrix.to(device), (1 - self.rho) * self.mask, self.eta.to('cuda:0'), self.mu_batch, self.num_words):\n",
    "            self.mu += tmp_mu\n",
    "\n",
    "        self.sigma = self.cq + self.zeta\n",
    "        for tmp_sigma in sigma_batch_generator(self.wordOccuranceMatrix.to(device), self.rho, self.sigma_batch, self.num_words):\n",
    "            self.sigma += tmp_sigma\n",
    "\n",
    "        uf_matrix = torch.zeros((self.num_docs, self.num_intensity), device=device)\n",
    "        uf_matrix.scatter_(1, self.user_count_list.unsqueeze(1), 1)\n",
    "        self.kappa[0] = self.delta + torch.einsum('u, uf -> f', [1 - self.iota, uf_matrix])\n",
    "        self.kappa[1] = self.delta + torch.einsum('u, uf -> f', [self.iota, uf_matrix])\n",
    "        del uf_matrix\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def calculate_ELBO(self):\n",
    "        factor = torch.zeros(20)\n",
    "\n",
    "        factor[1] = 2 * torch.lgamma(torch.sum(self.delta)) - 2 * torch.sum(torch.lgamma(self.delta)) + torch.einsum('f, if -> ', [self.delta - 1, torch.digamma(self.kappa) - torch.digamma(torch.sum(self.kappa, dim=1)).unsqueeze(1)])\n",
    "\n",
    "        factor[2] = (self.num_docs * torch.lgamma(torch.sum(self.gamma)) \n",
    "                     - self.num_docs * torch.sum(torch.lgamma(self.gamma)) \n",
    "                     + torch.einsum('i, ui -> ', [self.gamma - 1, torch.digamma(self.lamda) - torch.digamma(torch.sum(self.lamda, dim=1)).reshape(self.num_docs, 1)]))\n",
    "        \n",
    "        factor[3] = (self.num_docs * torch.lgamma(torch.sum(self.alpha)) \n",
    "                     - self.num_docs * torch.sum(torch.lgamma(self.alpha)) \n",
    "                     + torch.einsum('k, uk -> ', [self.alpha - 1, torch.digamma(self.tau) - torch.digamma(torch.sum(self.tau, dim=1)).reshape(self.num_docs, 1)]))\n",
    "\n",
    "        factor[4] = (self.num_topics * torch.lgamma(torch.sum(self.beta)) \n",
    "                     - self.num_topics * torch.sum(torch.lgamma(self.beta)) \n",
    "                     + torch.einsum('v, kv -> ', [self.beta - 1, torch.digamma(self.mu) - torch.digamma(torch.sum(self.mu, dim=1)).reshape(self.num_topics, 1)]))\n",
    "        \n",
    "        factor[5] = (torch.lgamma(torch.sum(self.zeta))\n",
    "                     - torch.sum(torch.lgamma(self.zeta))\n",
    "                     + torch.einsum('v, v -> ', [self.zeta - 1, torch.digamma(self.sigma) - torch.digamma(torch.sum(self.sigma))]))\n",
    "        \n",
    "        factor[6] = torch.einsum('v, v -> ', [self.cq, torch.digamma(self.sigma) - torch.digamma(torch.sum(self.sigma))])\n",
    "\n",
    "        factor[7] = torch.sum((1 - self.iota) * (torch.digamma(self.lamda[:, 1]) - torch.digamma(torch.sum(self.lamda, dim=1))) \n",
    "                              + self.iota * (torch.digamma(self.lamda[:, 0]) - torch.digamma(torch.sum(self.lamda, dim=1))))\n",
    "\n",
    "        factor[8] = torch.sum((1 - self.iota) * (torch.digamma(self.kappa_u[0]) - torch.digamma(torch.sum(self.kappa[0]))) \n",
    "                              + self.iota * (torch.digamma(self.kappa_u[1]) - torch.digamma(torch.sum(self.kappa[1]))))\n",
    "        \n",
    "        factor9_1 = torch.einsum('un, u -> ', [(1 - self.rho) * self.mask, torch.digamma(self.lamda[: , 1]) - torch.digamma(torch.sum(self.lamda, dim=1))])\n",
    "        factor9_2 = torch.einsum('un, u -> ', [self.rho, torch.digamma(self.lamda[: , 0]) - torch.digamma(torch.sum(self.lamda, dim=1))])\n",
    "        factor[9] = factor9_1 + factor9_2\n",
    "\n",
    "        factor[10] = torch.einsum('unk, uk -> ', [self.eta, torch.digamma(self.tau) - torch.digamma(torch.sum(self.tau, dim=1)).reshape(self.num_docs, 1)])\n",
    "        \n",
    "        factor11_1 = torch.einsum('un, unk, unk -> ', \n",
    "                                 [(1 - self.rho) * self.mask, \n",
    "                                  self.eta, \n",
    "                                  self.mask.view(self.num_docs, self.max_len, 1) * (torch.einsum('kun -> unk', [torch.digamma(self.mu_kun)]) - torch.digamma(torch.sum(self.mu, dim=1)))])\n",
    "        factor11_2 = torch.einsum('un, un -> ', \n",
    "                                 [self.rho, \n",
    "                                  torch.digamma(self.sigma_un) * self.mask - torch.digamma(torch.sum(self.sigma))])\n",
    "        factor[11] = factor11_1 + factor11_2\n",
    "\n",
    "        factor[12] = (-torch.sum(torch.lgamma(torch.sum(self.mu, dim=1))) \n",
    "                      + torch.sum(torch.lgamma(self.mu)) \n",
    "                      - torch.einsum('kv, kv -> ', [self.mu - 1, torch.digamma(self.mu) - torch.digamma(torch.sum(self.mu, dim=1)).reshape(self.num_topics, 1)]))\n",
    "\n",
    "        factor[13] = (-torch.sum(torch.lgamma(torch.sum(self.tau, dim=1))) \n",
    "                      + torch.sum(torch.lgamma(self.tau)) \n",
    "                      - torch.einsum('uk, uk -> ', [self.tau - 1, torch.digamma(self.tau) - torch.digamma(torch.sum(self.tau, dim=1)).reshape(self.num_docs, 1)]))\n",
    "\n",
    "        factor[14] = -torch.einsum('unk, unk -> ', [self.eta, torch.where(self.eta > 0, torch.log(self.eta), torch.zeros_like(self.eta))])\n",
    "\n",
    "        factor[15] = (-torch.sum(torch.lgamma(torch.sum(self.sigma))) \n",
    "                      + torch.sum(torch.lgamma(self.sigma)) \n",
    "                      - torch.einsum('v, v -> ', [self.sigma - 1, torch.digamma(self.sigma) - torch.digamma(torch.sum(self.sigma))]))\n",
    "        \n",
    "        factor[16] = -(torch.einsum('un, un -> ', [(1 - self.rho) * self.mask, torch.where((1 - self.rho) * self.mask > 0, torch.log((1 - self.rho) * self.mask), torch.zeros_like(self.rho))]) \n",
    "                       + torch.einsum('un, un -> ', [self.rho, torch.where(self.rho * self.mask > 0, torch.log(self.rho * self.mask), torch.zeros_like(self.rho))]))\n",
    "        \n",
    "        factor[17] = (-torch.sum(torch.lgamma(torch.sum(self.lamda, dim=1))) \n",
    "                      + torch.sum(torch.lgamma(self.lamda)) \n",
    "                      - torch.einsum('ui, ui -> ', [self.lamda - 1, torch.digamma(self.lamda) - torch.digamma(torch.sum(self.lamda, dim=1)).reshape(self.num_docs, 1)]))\n",
    "\n",
    "        factor[18] = -torch.sum((1 - self.iota) * torch.log(1 - self.iota) + self.iota * torch.log(self.iota))\n",
    "\n",
    "        factor[19] = -torch.sum(torch.lgamma(torch.sum(self.kappa, dim=1))) + torch.sum(torch.lgamma(self.kappa)) - torch.einsum('if, if -> ', [self.kappa - 1, torch.digamma(self.kappa) - torch.digamma(torch.sum(self.kappa, dim=1)).unsqueeze(1)])\n",
    "        \n",
    "        return torch.sum(factor).item()\n",
    "\n",
    "    def train_model(self, user_events_list, user_count_list, iter_times, is_draw_ELBO=False):\n",
    "        self.iter_times = iter_times\n",
    "        self.processProfiles(user_events_list, user_count_list)\n",
    "        if is_draw_ELBO:\n",
    "            animator = Animator(xlabel='epoch', xlim=[1, iter_times],legend=['ELBO'])\n",
    "            for iter in range(self.iter_times):\n",
    "                self.ref_update_variational_parameters()\n",
    "                self.ELBO.append(self.calculate_ELBO())\n",
    "                animator.add(iter, self.ELBO[iter])\n",
    "        else:\n",
    "            for iter in tqdm(range(self.iter_times)):\n",
    "                self.ref_update_variational_parameters()\n",
    "    \n",
    "    def predict(self, top_n):\n",
    "        normalized_mu = self.mu / torch.sum(self.mu, dim=1, keepdim=True)\n",
    "        normalized_lamda = self.lamda / torch.sum(self.lamda, dim=1).unsqueeze(dim=1)\n",
    "        normalized_sigma = self.sigma / torch.sum(self.sigma)\n",
    "        normalized_tau = self.tau / torch.sum(self.tau, dim=1).unsqueeze(dim=1)\n",
    "\n",
    "        # item_probability_matrix = torch.einsum('u, uk, kv -> uv', [normalized_lamda[:, 1], normalized_tau, normalized_mu]) + torch.einsum('u, v -> uv', [normalized_lamda[:, 0], normalized_sigma])\n",
    "\n",
    "        item_probability_matrix = torch.einsum('u, uk, kv -> uv', [normalized_lamda[:, 1].to('cpu'), normalized_tau.to('cpu'), normalized_mu.to('cpu')])\n",
    "        del normalized_tau, normalized_mu\n",
    "        torch.cuda.empty_cache() \n",
    "\n",
    "        # item_probability_matrix += torch.einsum('u, v -> uv', [normalized_lamda[:, 0], normalized_sigma])\n",
    "        item_probability_matrix += torch.ger(normalized_lamda[:, 0].to('cpu'), normalized_sigma.to('cpu'))\n",
    "        del normalized_lamda, normalized_sigma\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        all_users_predictions = recommend_N(item_probability_matrix, self.predict_candidate_list, top_n)\n",
    "        return all_users_predictions\n",
    "    \n",
    "    def evaluate(self, track_count_list, top_n_predict_list):\n",
    "        print(f'CR@{len(top_n_predict_list[0])} = ', calculate_CR(top_n_predict_list, self.predict_candidate_list))\n",
    "        print(f'NDCG@{len(top_n_predict_list[0])} = ', calculate_NDCG(top_n_predict_list, self.predict_candidate_list))\n",
    "\n",
    "        top_1_recommend_list = [recommend_list_for_one_user[0] for recommend_list_for_one_user in top_n_predict_list]\n",
    "        popularity = calculate_popularity(torch.tensor(track_count_list, ), top_1_recommend_list)\n",
    "        print(f'the populairity of recommend result: {popularity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = \n",
    "\n",
    "alpha = \n",
    "beta = \n",
    "gamma = \n",
    "zeta = \n",
    "delta = \n",
    "\n",
    "save_result = \n",
    "\n",
    "iter_times = \n",
    "random_state = \n",
    "mu_batch = \n",
    "sigma_batch = \n",
    "top_n = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myHB_Rec = HB_Rec(K, alpha, beta, gamma, zeta, delta, track_playcount_list, random_state, mu_batch, sigma_batch, num_tracks, predict_candidate_list)\n",
    "myHB_Rec.train_model(user_events_list, user_listen_count_list, iter_times, False)\n",
    "predictions = myHB_Rec.predict(top_n)\n",
    "myHB_Rec.evaluate(track_user_count_list, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
